)
obj <- FindNeighbors(obj, reduction = "integrated.scvi", dims = 1:30)
obj <- FindClusters(obj, resolution = 2, cluster.name = "scvi_clusters")
obj <- RunUMAP(obj, reduction = "integrated.scvi", dims = 1:30, reduction.name = "umap.scvi")
p2 <- DimPlot(
obj,
reduction = "umap.scvi",
group.by = c("Method", "predicted.celltype.l2", "scvi_clusters"),
combine = FALSE, label.size = 2
)
wrap_plots(c(p1, p2), ncol = 2, byrow = F)
# compare the expression of biological markers based on
# different clustering solutions, or visualize one method’s
# clustering solution on different UMAP visualizations.
p1 <- VlnPlot(
obj,
features = "rna_CD8A", group.by = "unintegrated_clusters"
) + NoLegend() + ggtitle("CD8A - Unintegrated Clusters")
# compare the expression of biological markers based on
# different clustering solutions, or visualize one method’s
# clustering solution on different UMAP visualizations.
p1 <- VlnPlot(
obj,
features = "rna_CD8A", group.by = "unintegrated_clusters"
) + NoLegend() + ggtitle("CD8A - Unintegrated Clusters")
p2 <- VlnPlot(
obj, "rna_CD8A",
group.by = "cca_clusters"
) + NoLegend() + ggtitle("CD8A - CCA Clusters")
p3 <- VlnPlot(
obj, "rna_CD8A",
group.by = "scvi_clusters"
) + NoLegend() + ggtitle("CD8A - scVI Clusters")
p1 | p2 | p3
p1
p2
p3
# UMAP clustering
obj <- RunUMAP(obj, reduction = "integrated.rpca", dims = 1:30, reduction.name = "umap.rpca")
p4 <- DimPlot(obj, reduction = "umap.unintegrated", group.by = c("cca_clusters"))
p5 <- DimPlot(obj, reduction = "umap.rpca", group.by = c("cca_clusters"))
p6 <- DimPlot(obj, reduction = "umap.scvi", group.by = c("cca_clusters"))
p4
p5
p6
p5
p6
# Once integrative analysis is complete, you can rejoin the layers
obj <- JoinLayers(obj)
obj
# Lastly, users can also perform integration using sctransform-normalized data
options(future.globals.maxSize = 3e+09)
obj <- SCTransform(obj)
obj <- RunPCA(obj, npcs = 30, verbose = F)
obj <- IntegrateLayers(
object = obj,
method = RPCAIntegration,
normalization.method = "SCT",
verbose = F
)
obj <- FindNeighbors(obj, dims = 1:30, reduction = "integrated.dr")
? FindNeighbors
obj <- FindNeighbors(obj, dims = 1:30, reduction = "pca")
obj <- FindClusters(obj, resolution = 2)
obj <- RunUMAP(obj, dims = 1:30, reduction = "integrated.dr")
# obj <- RunUMAP(obj, dims = 1:30, reduction = "integrated.dr")
# that reduction method was not found by the interpreter
obj <- RunUMAP(obj, dims = 1:30, reduction = "pca")
.rs.restartR()
library(Seurat)
# SeuratData includes the data to be used here
library(SeuratData)
library(SeuratWrappers)
library(Azimuth)
library(ggplot2)
library(patchwork)
library(reticulate)
options(future.globals.maxSize = 1e9)
# Load the PBMC systemic comparative analysis dataset
obj <- LoadData("pbmcsca")
# select only cells with at least 1000 features
obj <- subset(obj, nFeature_RNA > 1000)
# Classify cells
obj <- RunAzimuth(obj, reference = 'pbmcref')
obj
obj[["RNA"]] <- split(obj[["RNA"]], f = obj$Method)
obj
obj@meta.data$Method
obj <- NormalizeData(obj)
obj <- FindVariableFeatures(obj)
obj <- ScaleData(obj)
obj <- RunPCA(obj)
# Visualize a standard analysis without integration
# While a UMAP analysis is just a visualization of this, clustering
# this dataset would return predominantly batch-specific clusters.
# Especially if previous cell-type annotations were not available,
# this would make downstream analysis extremely challenging.
obj <- FindNeighbors(obj, dims = 1:30, reduction = "pca")
obj <- FindClusters(obj, resolution = 2, cluster.name = "unintegrated_clusters")
obj <- RunUMAP(obj, dims = 1:30, reduction = "pca", reduction.name = "umap.unintegrated")
# Visualize by batch and cell type annotation
# cell type annotation were previously added by Azimuth
DimPlot(obj, reduction = "umap.unintegrated",
group.by = "Method")
DimPlot(obj, reduction = "umap.unintegrated",
group.by = "predicted.celltype.l2")
# CCA integration
obj <- IntegrateLayers(
object = obj, method = CCAIntegration,
orig.reduction = "pca", new.reduction = "integrated.cca",
verbose = FALSE
)
# RPCA integration
obj <- IntegrateLayers(
object = obj, method = RPCAIntegration,
orig.reduction = "pca", new.reduction = "integrated.rpca",
verbose = FALSE
)
# Harmony integration
obj <- IntegrateLayers(
object = obj, method = HarmonyIntegration,
orig.reduction = "pca", new.reduction = "harmony",
verbose = FALSE
)
# FastMNN integration
obj <- IntegrateLayers(
object = obj, method = FastMNNIntegration,
new.reduction = "integrated.mnn",
verbose = FALSE
)
obj <- IntegrateLayers(
object = obj, method = scVIIntegration,
new.reduction = "integrated.scvi",
conda_env = "~/miniforge3/envs/scvi", verbose = FALSE
)
obj <- FindNeighbors(obj, reduction = "integrated.cca", dims = 1:30)
obj <- FindClusters(obj, resolution = 2, cluster.name = "cca_clusters")
obj <- RunUMAP(obj, reduction = "integrated.cca", dims = 1:30, reduction.name = "umap.cca")
p1 <- DimPlot(
obj,
reduction = "umap.cca",
group.by = c("Method", "predicted.celltype.l2", "cca_clusters"),
combine = FALSE, label.size = 2
)
p1
.rs.restartR()
shiny::runApp('jj/data_analysis/juanJovel/Rshiny/shiny_react.R')
runApp('jj/data_analysis/juanJovel/Rshiny/shiny_react.R')
install.packages("shiny.react")
library(shiny)
library(shiny.react)
dir <- '/Users/juanjovel/jj/dayhoff/pipelines/singleCells/kallisto_bus/kolby_pilot1_results/kallisto_results/counts_unfiltered'
library(BUSpaRse)
library(TENxBUSData)
library(ggplot2)
library(magrittr)
library(data.table)
library(Seurat)
library(SeuratData)
library(DropletUtils)
library(Matrix)
library(Azimuth)
library(patchwork)
theme_set(theme_bw())
ifnb <- LoadData("ifnb")
read_count_output <- function(dir, name, tcc = FALSE) {
dir <- normalizePath(dir, mustWork = TRUE)
m <- readMM(paste0(dir, "/", name, ".mtx"))
m <- Matrix::t(m)
m <- as(m, "dgCMatrix")
# The matrix read has cells in rows
ge <- if (tcc) ".ec.txt" else ".genes.txt"
con_genes <- file(paste0(dir, "/", name, ge))
con_bcs <- file(paste0(dir, "/", name, ".barcodes.txt"))
genes <- readLines(con_genes)
barcodes <- readLines(con_bcs)
colnames(m) <- barcodes
rownames(m) <- genes
close(con_genes)
close(con_bcs)
return(m)
}
dir <- '/Users/juanjovel/jj/dayhoff/pipelines/singleCells/kallisto_bus/kolby_pilot1_results/kallisto_results/counts_unfiltered'
res_mat <- read_count_output(dir,"cells_x_genes")
dim(res_mat)
tot_counts <- Matrix::colSums(res_mat)
summary(tot_counts)
tot_counts <- Matrix::colSums(res_mat)
summary(tot_counts)
# Compute barcode rank
bc_rank <- barcodeRanks(res_mat)
qplot(bc_rank$total, bc_rank$rank, geom = "line") +
geom_vline(xintercept = metadata(bc_rank)$knee, color = "blue", linetype = 2) +
geom_vline(xintercept = metadata(bc_rank)$inflection, color = "green", linetype = 2) +
annotate("text", y = 1000, x = 1.5 * c(metadata(bc_rank)$knee, metadata(bc_rank)$inflection),
label = c("knee", "inflection"), color = c("blue", "green")) +
scale_x_log10() +
scale_y_log10() +
labs(y = "Barcode rank", x = "Total UMI count")
# Filter the matrix
res_mat <- res_mat[, tot_counts > metadata(bc_rank)$inflection]
dim(res_mat)
# Create and preprocess the Seurat object
pbmc4k <- CreateSeuratObject(res_mat, min.cells = 3)
pbmc4k <- NormalizeData(pbmc4k, assay = "RNA", normalization.method = "LogNormalize", scale.factor = 10000)
pbmc4k <- ScaleData(pbmc4k, verbose = FALSE)
pbmc4k <- FindVariableFeatures(pbmc4k, verbose = FALSE)
# The RunAzimuth function can take a Seurat object as input
pbmc4k <- RunAzimuth(data.seurat,
reference = "pbmcref")
# The RunAzimuth function can take a Seurat object as input
pbmc4k <- RunAzimuth(pbmc4k,
reference = "pbmcref")
p1 <- DimPlot(data.seurat, group.by = "predicted.celltype.l2", label = TRUE, label.size = 3) + NoLegend()
p1 <- DimPlot(pbmc4k, group.by = "predicted.celltype.l2", label = TRUE, label.size = 3) + NoLegend()
p1
pbmc4k$predicted.celltype.l2
grepl("CD14 Mono", pbmc4k$predicted.celltype.l2)
grepl("CD16 Mono", pbmc4k$predicted.celltype.l2)
dir <- '/Users/juanjovel/jj/dayhoff/pipelines/singleCells/kallisto_bus/kolby_pilot1_results/kallisto_results/counts_unfiltered/test'
res_mat <- read_count_output(dir,"cells_x_genes")
dir <- '/Users/juanjovel/jj/dayhoff/pipelines/singleCells/kallisto_bus/kolby_pilot1_results/test'
res_mat <- read_count_output(dir,"cells_x_genes")
dir <- '/Users/juanjovel/jj/dayhoff/pipelines/singleCells/kallisto_bus/kolby_pilot1_results/test'
res_mat <- read_count_output(dir,"cells_x_genes")
dir <- '/Users/juanjovel/jj/dayhoff/pipelines/singleCells/kallisto_bus/kolby_pilot1_results/test'
res_mat <- read_count_output(dir,"cells_x_genes")
dir <- '/Users/juanjovel/jj/dayhoff/pipelines/singleCells/kallisto_bus/kolby_pilot1_results/test'
res_mat <- read_count_output(dir,"cells_x_genes")
dim(res_mat)
tot_counts <- Matrix::colSums(res_mat)
summary(tot_counts)
# Compute barcode rank
bc_rank <- barcodeRanks(res_mat)
qplot(bc_rank$total, bc_rank$rank, geom = "line") +
geom_vline(xintercept = metadata(bc_rank)$knee, color = "blue", linetype = 2) +
geom_vline(xintercept = metadata(bc_rank)$inflection, color = "green", linetype = 2) +
annotate("text", y = 1000, x = 1.5 * c(metadata(bc_rank)$knee, metadata(bc_rank)$inflection),
label = c("knee", "inflection"), color = c("blue", "green")) +
scale_x_log10() +
scale_y_log10() +
labs(y = "Barcode rank", x = "Total UMI count")
# Filter the matrix
res_mat <- res_mat[, tot_counts > metadata(bc_rank)$inflection]
dim(res_mat)
# Create and preprocess the Seurat object
pbmc4k <- CreateSeuratObject(res_mat, min.cells = 3)
pbmc4k <- NormalizeData(pbmc4k, assay = "RNA", normalization.method = "LogNormalize", scale.factor = 10000)
pbmc4k <- ScaleData(pbmc4k, verbose = FALSE)
pbmc4k <- FindVariableFeatures(pbmc4k, verbose = FALSE)
# The RunAzimuth function can take a Seurat object as input
pbmc4k <- RunAzimuth(pbmc4k,
reference = "pbmcref")
p1 <- DimPlot(pbmc4k, group.by = "predicted.celltype.l2", label = TRUE, label.size = 3) + NoLegend()
p1
# Ensure that seurat_annotations is correctly assigned as a factor
pbmc4k$seurat_annotations <- factor(pbmc4k$predicted.celltype.l2)
# Set identities using the actual data from seurat_annotations
Idents(pbmc4k) <- pbmc4k$seurat_annotations
table(Idents(pbmc4k))
Idents(pbmc4k)
monocyte.de.markers <- FindMarkers(pbmc4k, ident.1 = "CD16 Mono",
ident.2 = "CD14 Mono")
pbmc4k <- NormalizeData(pbmc4k, assay = "RNA", normalization.method = "LogNormalize", scale.factor = 10000)
monocyte.de.markers <- FindMarkers(pbmc4k, ident.1 = "CD16 Mono",
ident.2 = "CD14 Mono")
# view results
head(monocyte.de.markers)
pbmc4k <- RunAzimuth(pbmc4k,
reference = "pbmcref")
p1 <- DimPlot(pbmc4k, group.by = "predicted.celltype.l2", label = TRUE, label.size = 3) + NoLegend()
p1
monocyte.de.markers.LR <- FindMarkers(ifnb, ident.1 = "CD14 Mono", ident.2 = "CD16 Mono", test.use = "LR")
ifnb <- LoadData("ifnb")
Idents(ifnb) <- "seurat_annotations"
ifnb$seurat_annotations
ifnb$stim
head(ifnb$stim)
tail(ifnb$stim)
# Since this dataset contains treatment information (control versus stimulated
# with interferon-beta), we can also ask what genes change in different
# conditions for cells of the same type. First, we create a column in the
# meta.data slot to hold both the cell type and treatment information and
# switch the current Idents to that column. Then we use FindMarkers() to find
# the genes that are different between control and stimulated CD14 monocytes.
ifnb$celltype.stim <- paste(ifnb$seurat_annotations, ifnb$stim, sep = "_")
ifnb$celltype.stim
Idents(ifnb) <- "celltype.stim"
ifnb$celltype.stim
mono.de <- FindMarkers(ifnb, ident.1 = "CD14 Mono_STIM",
ident.2 = "CD14 Mono_CTRL", verbose = FALSE)
head(mono.de, n = 10)
monocyte.de.markers.wilcox_limma <- FindMarkers(ifnb, ident.1 = "CD14 Mono", ident.2 = "CD16 Mono", test.use = "wilcox_limma")
# Next one requires installing package MAST
# BiocManager::install("MAST")
monocyte.de.markers.mast   <- FindMarkers(ifnb, ident.1 = "CD14 Mono", ident.2 = "CD16 Mono", test.use = "MAST")
# Next one requires installing package MAST
# BiocManager::install("MAST")
monocyte.de.markers.mast   <- FindMarkers(ifnb, ident.1 = "CD14 Mono_CTRL", ident.2 = "CD14 Mono_STIM", test.use = "MAST")
head(monocyte.de.markers.mast)
monocyte.de.markers.deseq2_pbmc4k <- FindMarkers(pbmc4k, ident.1 = "CD14 Mono", ident.2 = "CD16 Mono", test.use = "DESeq2")
head(monocyte.de.markers.deseq2_pbmc4k)
signRes <- subset(monocyte.de.markers.deseq2_pbmc4k, p_val_adj < 0.05)
signRes
nrow(signRes)
source("~/Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/basilHubbard/shunZhang/makeBarPlots.R", echo=TRUE)
source("~/Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/basilHubbard/shunZhang/makeBarPlots.R", echo=TRUE)
source("~/Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/basilHubbard/shunZhang/makeBarPlots.R", echo=TRUE)
source("~/Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/basilHubbard/shunZhang/makeBarPlots.R", echo=TRUE)
library(Signag)
devtools::install_version(package = 'Signac', version = package_version('0.2.5'))
install.packages("gggenes")
devtools::install_version(package = 'Signac', version = package_version('0.2.5'))
library(Signag)
devtools::install_github("stuart-lab/signac", ref = "develop")
devtools::install_github("stuart-lab/signac", ref = "develop")
devtools::install_github("stuart-lab/signac", ref = "develop")
pkgbuild::check_build_tools(debug = TRUE)
devtools::install_github("stuart-lab/signac", ref = "develop")
pkgbuild::check_build_tools(debug = TRUE)
pkgbuild::check_build_tools(debug = TRUE)
devtools::install_github("stuart-lab/signac", ref = "develop")
pkgbuild::check_build_tools(debug = TRUE)
pkgbuild::check_build_tools(debug = TRUE)
pkgbuild::check_build_tools(debug = TRUE)
pkgbuild::check_build_tools(debug = TRUE)
export CPPFLAGS="-I/opt/homebrew/opt/llvm/include"
pkgbuild::check_build_tools(debug = TRUE)
devtools::install_github("timoast/signac")
# https://satijalab.org/seurat/articles/seurat5_integration
library(Seurat)
library(SeuratData)
library(SeuratWrappers)
library(Azimuth)
options(future.globals.maxSize = 1e9)
library(Azimuth)
packageVersion("shiny")
shiny::runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1/app.R')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1')
library(bslib)
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1/example2')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1/example2')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1/example2')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/tutorials/shinyBook1/chapter1/example2')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/example3.R')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/example3.R')
runApp('Library/CloudStorage/OneDrive-UniversityofCalgary/jj/UofC/data_analysis/juanJovel/Rshiny/example3.R')
library(Seurat)
library(SeuratData)
library(ggplot2)
library(Azimuth)
library(patchwork)
InstallData("panc8")
panc8 <- LoadData("panc8")
panc8 <- RunAzimuth(panc8, reference = "pancreasref")
p1 <- DimPlot(panc8, group.by = "celltype", label = TRUE, label.size = 3) + NoLegend()
p1
# load required libraries
library(Seurat)    # main library for the analysis of scRNAseq data
library(tximport)  # used to import text files produced by salmon alevin
library(tidyverse) # includes several R packages needed
library(patchwork)
# set the working directory
setwd('/Users/juanjovel/OneDrive/jj/UofC/data_analysis/juanJovel/courses/2024/scRNAseq/final_version')
# define the path of the alevin directory
alevin_dir = "alevin_quants"
# get subdirectories with name ending in '_alevin_output'
# only useful if there are other directories with names
# not ending in '_alevin_output'
alevin_subdirs <- list.dirs(path = alevin_dir, full.names = TRUE, recursive = F)
# Filter subdirectories ending with '_alevin_output'
alevin_subdirs <- alevin_subdirs[grep("_alevin_output$", alevin_subdirs)]
# Extract the barcodes (first part of the name) as sample names
sample_names <- gsub('_alevin_ouput$', '', basename(alevin_subdirs))
# Initialize a list to store Seurat objects
seurat_list <- list()
# iterate along all alevin subdirectories and import each dataset
for (i in seq_along(alevin_subdirs)) {
# File path to the 'quants_mat.gz file, where the CB and UMIs lists are too
files <- file.path(alevin_subdirs[i], "alevin", "quants_mat.gz")
names(files) <- sample_names[i]
# import nedeed files with tximport
txi <- tximport(files, type = "alevin")
# extract counts data
data <- txi$counts
# Create a Seurat object per dataset
seurat_object <- CreateSeuratObject(counts = data, project = sample_names[i])
# store the Seurat object in the objects list
seurat_list[[i]] <- seurat_object
}
# Function to generate QC violin plots
generateQCPlot <- function(obj, barcode, suffix = "") {
filename <- paste0(barcode, '_seurat_QCplot', suffix, '.png')
png(filename, width = 12, height = 9, units = 'in', pointsize = 24, res = 300)
p <- VlnPlot(obj, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3, cols = 'dodgerblue')
print(p)
dev.off()
}
# Function to generate feature relationship scatter plots
generateFeatureRelationshipPlot <- function(obj, barcode, suffix = "") {
filename <- paste0(barcode, '_seurat_feature-relationship', suffix, '.png')
png(filename, width = 12, height = 9, units = 'in', pointsize = 24, res = 300)
plot1 <- FeatureScatter(obj, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(obj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
print(plot1 + plot2)
dev.off()
}
# Preprocess individual libraries
for (i in seq_along(seurat_list)) {
# Access the Seurat object using the index
obj <- seurat_list[[i]]
# Extract barcodes to use as dataset identifiers
barcode <- gsub('_alevin_output', '', unique(obj@meta.data$orig.ident))
# Add identity to each dataset
obj$orig.ident <- barcode
### QC ###
# Calculate nFeature_RNA and nCount_RNA if they don't exist
obj <- AddMetaData(obj, metadata = Matrix::colSums(obj@assays$RNA$counts > 0), col.name = "nFeature_RNA")
obj <- AddMetaData(obj, metadata = Matrix::colSums(obj@assays$RNA$counts), col.name = "nCount_RNA")
# Calculate the percentage of mitochondrial reads
obj[["percent.mt"]] <- PercentageFeatureSet(obj, pattern = "^MT-")
# Generate initial QC plot and feature relationship plot
generateQCPlot(obj, barcode)
generateFeatureRelationshipPlot(obj, barcode)
# Filter cells based on QC criteria
obj <- subset(obj, subset = nFeature_RNA > 300 & nFeature_RNA < 2500 & percent.mt < 5 &
nCount_RNA > 500 & nCount_RNA < 10000)
# Generate post-filtering QC plot and feature relationship plot
generateQCPlot(obj, barcode, suffix = "_AF")
generateFeatureRelationshipPlot(obj, barcode, suffix = "_AF")
# Normalize counts in each of the datasets
obj <- NormalizeData(obj)
obj <- FindVariableFeatures(obj)
obj <- ScaleData(obj)
# Save changes back to the list
seurat_list[[i]] <- obj
}
# Preprocess individual libraries
for (i in seq_along(seurat_list)) {
# Access the Seurat object using the index
obj <- seurat_list[[i]]
# Extract barcodes to use as dataset identifiers
barcode <- gsub('_alevin_output', '', unique(obj@meta.data$orig.ident))
# Add identity to each dataset
obj$orig.ident <- barcode
### QC ###
# Calculate nFeature_RNA and nCount_RNA if they don't exist
obj <- AddMetaData(obj, metadata = Matrix::colSums(obj@assays$RNA$counts > 0), col.name = "nFeature_RNA")
obj <- AddMetaData(obj, metadata = Matrix::colSums(obj@assays$RNA$counts), col.name = "nCount_RNA")
# Calculate the percentage of mitochondrial reads
obj[["percent.mt"]] <- PercentageFeatureSet(obj, pattern = "^MT-")
# Generate initial QC plot and feature relationship plot
generateQCPlot(obj, barcode)
generateFeatureRelationshipPlot(obj, barcode)
# Filter cells based on QC criteria
obj <- subset(obj, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5 &
nCount_RNA > 500 & nCount_RNA < 10000)
# Generate post-filtering QC plot and feature relationship plot
generateQCPlot(obj, barcode, suffix = "_AF")
generateFeatureRelationshipPlot(obj, barcode, suffix = "_AF")
# Normalize counts in each of the datasets
obj <- NormalizeData(obj)
obj <- FindVariableFeatures(obj)
obj <- ScaleData(obj)
# Save changes back to the list
seurat_list[[i]] <- obj
}
# Merge the datasets
# Extract barcodes from each Seurat object in seurat_list
barcodes <- sapply(seurat_list, function(obj) unique(obj$orig.ident))
barcodes
barcodes2 <- lapply(seurat_list, function(obj) unique(obj$orig.ident))
barcodes2
class(barcodes)
class(barcodes2)
# Merge Seurat objects using the extracted barcodes as cell IDs
merged_obj <- merge(
x = seurat_list[[1]],
y = seurat_list[2:length(seurat_list)],
add.cell.ids = barcodes,
project = "pbmc3k"
)
# Preprocess the merged data
merged_obj <- NormalizeData(merged_obj)
merged_obj <- FindVariableFeatures(merged_obj)
merged_obj <- ScaleData(merged_obj)
merged_obj <- RunPCA(merged_obj, npcs = 30)
# Find integration anchors
anchors <- FindIntegrationAnchors(object.list = SplitObject(merged_obj, split.by = "orig.ident"), dims = 1:30)
# Integrate data
integrated_data <- IntegrateData(anchorset = anchors, dims = 1:30)
integrated_data@assays$integrated$data
# Proceed with downstream analysis on the integrated data
integrated_data <- ScaleData(integrated_data)
integrated_data <- RunPCA(integrated_data, npcs = 30)
integrated_data$orig.ident
# Function to save plots
saveSinglePlot <- function(plot, filename){
png(filename, width = 8, height = 6, units = 'in',  res = 300)
print(plot)
dev.off()
}
plot <- VizDimLoadings(integrated_data, dims = 1:2, reduction = "pca")
saveSinglePlot(plot, 'VizDimLoadings_int-4-samples.png')
plot <- DimHeatmap(integrated_data, dims = 1:8, cells = 500, balanced = TRUE)
saveSinglePlot(plot, 'DimHeatmap_int-4-samples.png')
plot <- ElbowPlot(integrated_data)
saveSinglePlot(plot, 'ElbowPlot_int-4-samples.png')
plot <- DimHeatmap(integrated_data, dims = 1:8, cells = 500, balanced = TRUE)
saveSinglePlot(plot, 'DimHeatmap_int-4-samples.png')
